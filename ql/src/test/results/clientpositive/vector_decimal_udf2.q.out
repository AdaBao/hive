PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2_txt
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2_txt
POSTHOOK: type: DROPTABLE
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE DECIMAL_UDF2_txt (key decimal(20,10), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_UDF2_txt
POSTHOOK: query: CREATE TABLE DECIMAL_UDF2_txt (key decimal(20,10), value int)
ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ' '
STORED AS TEXTFILE
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_UDF2_txt
PREHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv7.txt' INTO TABLE DECIMAL_UDF2_txt
PREHOOK: type: LOAD
#### A masked pattern was here ####
PREHOOK: Output: default@decimal_udf2_txt
POSTHOOK: query: LOAD DATA LOCAL INPATH '../../data/files/kv7.txt' INTO TABLE DECIMAL_UDF2_txt
POSTHOOK: type: LOAD
#### A masked pattern was here ####
POSTHOOK: Output: default@decimal_udf2_txt
PREHOOK: query: CREATE TABLE DECIMAL_UDF2 (key decimal(20,10), value int)
STORED AS ORC
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@DECIMAL_UDF2
POSTHOOK: query: CREATE TABLE DECIMAL_UDF2 (key decimal(20,10), value int)
STORED AS ORC
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@DECIMAL_UDF2
PREHOOK: query: INSERT OVERWRITE TABLE DECIMAL_UDF2 SELECT * FROM DECIMAL_UDF2_txt
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2_txt
PREHOOK: Output: default@decimal_udf2
POSTHOOK: query: INSERT OVERWRITE TABLE DECIMAL_UDF2 SELECT * FROM DECIMAL_UDF2_txt
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2_txt
POSTHOOK: Output: default@decimal_udf2
POSTHOOK: Lineage: decimal_udf2.key SIMPLE [(decimal_udf2_txt)decimal_udf2_txt.FieldSchema(name:key, type:decimal(20,10), comment:null), ]
POSTHOOK: Lineage: decimal_udf2.value SIMPLE [(decimal_udf2_txt)decimal_udf2_txt.FieldSchema(name:value, type:int, comment:null), ]
PREHOOK: query: insert into DECIMAL_UDF2 values (NULL, NULL)
PREHOOK: type: QUERY
PREHOOK: Output: default@decimal_udf2
POSTHOOK: query: insert into DECIMAL_UDF2 values (NULL, NULL)
POSTHOOK: type: QUERY
POSTHOOK: Output: default@decimal_udf2
POSTHOOK: Lineage: decimal_udf2.key EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col1, type:string, comment:), ]
POSTHOOK: Lineage: decimal_udf2.value EXPRESSION [(values__tmp__table__1)values__tmp__table__1.FieldSchema(name:tmp_values_col2, type:string, comment:), ]
PREHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2 WHERE key = 10
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2 WHERE key = 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_udf2
            Statistics: Num rows: 39 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                projectedOutputColumns: [0, 1]
            Filter Operator
              Filter Vectorization:
                  className: VectorFilterOperator
                  native: true
                  predicateExpression: FilterDecimalColEqualDecimalScalar(col 0, val 10)
              predicate: (key = 10) (type: boolean)
              Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: NaN (type: double), NaN (type: double), 1.4711276743037347 (type: double), -0.8390715290764524 (type: double), -0.5440211108893698 (type: double), 0.6483608274590866 (type: double), 0.17453292519943295 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumns: [2, 3, 4, 5, 6, 7, 8]
                    selectExpressions: ConstantVectorExpression(val NaN) -> 2:double, ConstantVectorExpression(val NaN) -> 3:double, ConstantVectorExpression(val 1.4711276743037347) -> 4:double, ConstantVectorExpression(val -0.8390715290764524) -> 5:double, ConstantVectorExpression(val -0.5440211108893698) -> 6:double, ConstantVectorExpression(val 0.6483608274590866) -> 7:double, ConstantVectorExpression(val 0.17453292519943295) -> 8:double
                Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          groupByVectorOutput: true
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: false
          vectorized: true

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2 WHERE key = 10
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2 WHERE key = 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
NaN	NaN	1.4711276743037347	-0.8390715290764524	-0.5440211108893698	0.6483608274590866	0.17453292519943295
PREHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT SUM(HASH(*))
FROM (SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2) q
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT SUM(HASH(*))
FROM (SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2) q
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_udf2
            Statistics: Num rows: 39 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                projectedOutputColumns: [0, 1]
            Select Operator
              expressions: hash(acos(key),asin(key),atan(key),cos(key),sin(key),tan(key),radians(key)) (type: int)
              outputColumnNames: _col0
              Select Vectorization:
                  className: VectorSelectOperator
                  native: true
                  projectedOutputColumns: [10]
                  selectExpressions: VectorUDFAdaptor(hash(acos(key),asin(key),atan(key),cos(key),sin(key),tan(key),radians(key)))(children: FuncACosDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 3:double, FuncASinDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 4:double, FuncATanDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 5:double, FuncCosDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 6:double, FuncSinDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 7:double, FuncTanDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 8:double, FuncRadiansDoubleToDouble(col 2)(children: CastDecimalToDouble(col 0) -> 2:double) -> 9:double) -> 10:int
              Statistics: Num rows: 39 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
              Group By Operator
                aggregations: sum(_col0)
                Group By Vectorization:
                    aggregators: VectorUDAFSumLong(col 10) -> bigint
                    className: VectorGroupByOperator
                    vectorOutput: true
                    native: false
                    projectedOutputColumns: [0]
                mode: hash
                outputColumnNames: _col0
                Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                Reduce Output Operator
                  sort order: 
                  Reduce Sink Vectorization:
                      className: VectorReduceSinkOperator
                      native: false
                      nativeConditionsMet: hive.vectorized.execution.reducesink.new.enabled IS true, Not ACID UPDATE or DELETE IS true, No buckets IS true, No TopN IS true, No DISTINCT columns IS true, BinarySortableSerDe for keys IS true, LazyBinarySerDe for values IS true
                      nativeConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false, Uniform Hash IS false
                  Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
                  value expressions: _col0 (type: bigint)
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          groupByVectorOutput: true
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: true
          vectorized: true
      Reduce Vectorization:
          enabled: false
          enableConditionsMet: hive.vectorized.execution.reduce.enabled IS true
          enableConditionsNotMet: hive.execution.engine mr IN [tez, spark] IS false
      Reduce Operator Tree:
        Group By Operator
          aggregations: sum(VALUE._col0)
          Group By Vectorization:
              vectorOutput: false
              native: false
              projectedOutputColumns: null
          mode: mergepartial
          outputColumnNames: _col0
          Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
          File Output Operator
            compressed: false
            Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
            table:
                input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT SUM(HASH(*))
FROM (SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2) q
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: SELECT SUM(HASH(*))
FROM (SELECT acos(key), asin(key), atan(key), cos(key), sin(key), tan(key), radians(key)
FROM DECIMAL_UDF2) q
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
-11084548840
PREHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2 WHERE key = 10
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: EXPLAIN VECTORIZATION EXPRESSION
SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2 WHERE key = 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
PLAN VECTORIZATION:
  enabled: true
  enabledConditionsMet: [hive.vectorized.execution.enabled IS true]

STAGE DEPENDENCIES:
  Stage-1 is a root stage
  Stage-0 depends on stages: Stage-1

STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: decimal_udf2
            Statistics: Num rows: 39 Data size: 4296 Basic stats: COMPLETE Column stats: NONE
            TableScan Vectorization:
                native: true
                projectedOutputColumns: [0, 1]
            Filter Operator
              Filter Vectorization:
                  className: VectorFilterOperator
                  native: true
                  predicateExpression: FilterDecimalColEqualDecimalScalar(col 0, val 10)
              predicate: (key = 10) (type: boolean)
              Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: 22026.465794806718 (type: double), 2.302585092994046 (type: double), 2.302585092994046 (type: double), 1.0 (type: double), log(10, value) (type: double), log(value, 10) (type: double), 1.0 (type: double), 3.1622776601683795 (type: double)
                outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7
                Select Vectorization:
                    className: VectorSelectOperator
                    native: true
                    projectedOutputColumns: [2, 3, 4, 5, 6, 7, 8, 9]
                    selectExpressions: ConstantVectorExpression(val 22026.465794806718) -> 2:double, ConstantVectorExpression(val 2.302585092994046) -> 3:double, ConstantVectorExpression(val 2.302585092994046) -> 4:double, ConstantVectorExpression(val 1.0) -> 5:double, FuncLogWithBaseLongToDouble(col 1) -> 6:double, VectorUDFAdaptor(log(value, 10)) -> 7:double, ConstantVectorExpression(val 1.0) -> 8:double, ConstantVectorExpression(val 3.1622776601683795) -> 9:double
                Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  File Sink Vectorization:
                      className: VectorFileSinkOperator
                      native: false
                  Statistics: Num rows: 19 Data size: 2092 Basic stats: COMPLETE Column stats: NONE
                  table:
                      input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                      output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
      Execution mode: vectorized
      Map Vectorization:
          enabled: true
          enabledConditionsMet: hive.vectorized.use.vectorized.input.format IS true
          groupByVectorOutput: true
          inputFileFormats: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          allNative: false
          usesVectorUDFAdaptor: true
          vectorized: true

  Stage: Stage-0
    Fetch Operator
      limit: -1
      Processor Tree:
        ListSink

PREHOOK: query: SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2 WHERE key = 10
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2 WHERE key = 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
22026.465794806718	2.302585092994046	2.302585092994046	1.0	1.0	1.0	1.0	3.1622776601683795
PREHOOK: query: SELECT SUM(HASH(*))
FROM (SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2) q
PREHOOK: type: QUERY
PREHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
POSTHOOK: query: SELECT SUM(HASH(*))
FROM (SELECT
  exp(key), ln(key),
  log(key), log(key, key), log(key, value), log(value, key),
  log10(key), sqrt(key)
FROM DECIMAL_UDF2) q
POSTHOOK: type: QUERY
POSTHOOK: Input: default@decimal_udf2
#### A masked pattern was here ####
2259937441
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2_txt
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@decimal_udf2_txt
PREHOOK: Output: default@decimal_udf2_txt
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2_txt
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@decimal_udf2_txt
POSTHOOK: Output: default@decimal_udf2_txt
PREHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@decimal_udf2
PREHOOK: Output: default@decimal_udf2
POSTHOOK: query: DROP TABLE IF EXISTS DECIMAL_UDF2
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@decimal_udf2
POSTHOOK: Output: default@decimal_udf2
